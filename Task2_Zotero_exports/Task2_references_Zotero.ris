TY  - JOUR
TI  - GUI Element Detection Using SOTA YOLO Deep Learning Models
AU  - Daneshvar, Seyed Shayan
AU  - Wang, Shaowei
AB  - Detection of Graphical User Interface (GUI) elements is a crucial task for automatic code generation from images and sketches, GUI testing, and GUI search. Recent studies have leveraged both old-fashioned and modern computer vision (CV) techniques. Oldfashioned methods utilize classic image processing algorithms (e.g. edge detection and contour detection) and modern methods use mature deep learning solutions for general object detection tasks. GUI element detection, however, is a domain-specific case of object detection, in which objects overlap more often, and are located very close to each other, plus the number of object classes is considerably lower, yet there are more objects in the images compared to natural images. Hence, the studies that have been carried out on comparing various object detection models, might not apply to GUI element detection. In this study, we evaluate the performance of the four most recent successful YOLO models for general object detection tasks on GUI element detection and investigate their accuracy performance in detecting various GUI elements.
DA  - 2024/08/07/
PY  - 2024
DO  - 10.48550/arXiv.2408.03507
DP  - arXiv.org
UR  - http://arxiv.org/abs/2408.03507
Y2  - 2025/04/17/11:02:43
L2  - http://arxiv.org/abs/2408.03507
L4  - http://arxiv.org/pdf/2408.03507v1
N1  - <div data-schema-version="9"><p>This article examines how state-of-the-art YOLO models perform in detecting GUI components. It focuses on objective metrics such as accuracy and recall, making it highly relevant for bench marking OmniParserâ€™s results.</p>
</div>
KW  - Deep Learning
KW  - GUI Automation
KW  - Benchmarking
ER  - 

TY  - CONF
TI  - Mobile User Interface Element Detection Via Adaptively Prompt Tuning
AU  - Gu, Zhangxuan
AU  - Xu, Zhuoer
AU  - Chen, Haoxing
AU  - Lan, Jun
AU  - Meng, Changhua
AU  - Wang, Weiqiang
T2  - 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
AB  - Recent object detection approaches rely on pretrained vision-language models for image-text alignment. However, they fail to detect the Mobile User Interface (MUI) element since it contains additional OCR information, which describes its content and function but is often ignored. In this paper, we develop a new MUI element detection dataset named MUI-zh and propose an Adaptively Prompt Tuning (APT) module to take advantage of discriminating OCR information. APT is a lightweight and effective module to jointly optimize category prompts across different modalities. For every element, APT uniformly encodes its visual features and OCR descriptions to dynamically adjust the representation of frozen category prompts. We evaluate the effectiveness of our plug-and-play APT upon several existing CLIP-based detectors for both standard and openvocabulary MUI element detection. Extensive experiments show that our method achieves considerable improvements on two datasets. The datasets is available at github. com/antmachineintelligence/MUI-zh.
C1  - Vancouver, BC, Canada
C3  - 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
DA  - 2023/06//
PY  - 2023
DO  - 10.1109/CVPR52729.2023.01073
DP  - DOI.org (Crossref)
SP  - 11155
EP  - 11164
LA  - en
PB  - IEEE
SN  - 979-8-3503-0129-8
UR  - https://ieeexplore.ieee.org/document/10205239/
Y2  - 2025/04/17/11:05:15
L1  - https://openaccess.thecvf.com/content/CVPR2023/papers/Gu_Mobile_User_Interface_Element_Detection_via_Adaptively_Prompt_Tuning_CVPR_2023_paper.pdf
N1  - <div data-schema-version="9"><p>This study investigates a prompt tuning approach for mobile GUI detection. It provides useful insights into model adaptability, which aligns with the hypothesis on performance variability across interface complexities.</p>
</div>
KW  - Deep Learning
KW  - Benchmarking
ER  - 

TY  - JOUR
TI  - How Expertise Affects a Digital-Rights-Management-Sharing Application's Usability
AU  - Lah, Urska
AU  - Lewis, James R.
T2  - IEEE Software
AB  - Researchers performed a usability study of a digital-rights-management sharing (DRMS) application with which users protect and share digital files. Besides the standard goal of identifying usability problems, the study investigated how expertise affects objective and perceived usability, the correlations among the usability metrics, and how the usability outcomes compared with emerging norms. The researchers divided the 18 study participants into two groups of nine according to skill level. The participants performed seven DRMS tasks. The groups differed significantly in objective usability (successful task completions, errors, and completion times) and perceived usability (ratings of a variant of the System Usability Scale [SUS]). Two correlations were statistically significant (success with the SUS and success with errors); all six possible correlations were in the expected direction. On the basis of the published norms, the overall success rate was below average; the SUS's overall mean was average. The main takeaways for practitioners are two practical examples. The first involved using independently derived benchmarks to assess the perceived usability and effectiveness; the second involved testing different skill groups.
DA  - 2016/05//
PY  - 2016
DO  - 10.1109/MS.2015.104
DP  - IEEE Xplore
VL  - 33
IS  - 3
SP  - 76
EP  - 82
SN  - 1937-4194
UR  - https://ieeexplore.ieee.org/document/7281117
Y2  - 2025/04/17/11:05:31
L2  - https://ieeexplore.ieee.org/document/7281117
N1  - <div data-schema-version="9"><p>The article outlines an early implementation of AI-based GUI testing. Though limited to simpler layouts, it helps contextualize the evolution of automated interface detection over time.</p>
</div>
KW  - System Usability Scale
KW  - GUI Automation
KW  - Experimental Design
ER  - 

TY  - CONF
TI  - Object Detection for Graphical User Interface: Old Fashioned or Deep Learning or a Combination?
AU  - Chen, Jieshan
AU  - Xie, Mulong
AU  - Xing, Zhenchang
AU  - Chen, Chunyang
AU  - Xu, Xiwei
AU  - Zhu, Liming
AU  - Li, Guoqiang
AB  - Detecting Graphical User Interface (GUI) elements in GUI images is a domain-specific object detection task. It supports many software engineering tasks, such as GUI animation and testing, GUI search and code generation. Existing studies for GUI element detection directly borrow the mature methods from computer vision (CV) domain, including old fashioned ones that rely on traditional image processing features (e.g., canny edge, contours), and deep learning models that learn to detect from large-scale GUI data. Unfortunately, these CV methods are not originally designed with the awareness of the unique characteristics of GUIs and GUI elements and the high localization accuracy of the GUI element detection task. We conduct the first large-scale empirical study of seven representative GUI element detection methods on over 50k GUI images to understand the capabilities, limitations and effective designs of these methods. This study not only sheds the light on the technical challenges to be addressed but also informs the design of new GUI element detection methods. We accordingly design a new GUI-specific old-fashioned method for non-text GUI element detection which adopts a novel top-down coarse-to-fine strategy, and incorporate it with the mature deep learning model for GUI text detection.Our evaluation on 25,000 GUI images shows that our method significantly advances the start-of-the-art performance in GUI element detection.
C3  - Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering
DA  - 2020/11/08/
PY  - 2020
DO  - 10.1145/3368089.3409691
DP  - arXiv.org
SP  - 1202
EP  - 1214
ST  - Object Detection for Graphical User Interface
UR  - http://arxiv.org/abs/2008.05132
Y2  - 2025/04/17/11:07:11
L2  - http://arxiv.org/abs/2008.05132
L4  - http://arxiv.org/pdf/2008.05132v2
N1  - <div data-schema-version="9"><p>The paper explores both traditional image processing and deep learning techniques, offering a well-balanced approach. It supports the rationale for using a mixed methods strategy in this research.</p>
</div>
KW  - GUI Automation
KW  - Hybrid Methodology
ER  - 

TY  - CONF
TI  - Autonomous GUI Testing using Deep Reinforcement Learning
AU  - Saber, Salma
AU  - Elbadry, Fatma
AU  - Negm, Hagar
AU  - El-Ershad, Rana Abu
AU  - Magdy, Omar
AU  - Bahnassawi, Mohamed
AU  - El Adawi, Reem
AU  - Bayoumi, AbdElMoniem
T2  - 2021 17th International Computer Engineering Conference (ICENCO)
AB  - Automating software testing looks forward to speeding up testing processes and ensuring possible replication of discovered software bugs. However, Automating the GUI testing process is highly challenging due to the need for human intervention to determine actions and assess outcomes. We introduce a novel approach to fully automate GUI testing using deep reinforcement learning. Our deep reinforcement learning model discovers all system states and determines possible testing sequences. The automated testing agent starts with exploring the tested environment to learn the most efficient paths for reaching maximum coverage while discovering GUI bugs. In this case, testers could focus more on functionality testing to improve the overall software quality. We evaluated the developed model on a couple of industry products, and it showed a substantial increase in coverage than random testing.
C3  - 2021 17th International Computer Engineering Conference (ICENCO)
DA  - 2021/12//
PY  - 2021
DO  - 10.1109/ICENCO49852.2021.9715282
DP  - IEEE Xplore
SP  - 94
EP  - 100
UR  - https://ieeexplore.ieee.org/document/9715282
Y2  - 2025/04/17/11:07:52
L2  - https://ieeexplore.ieee.org/document/9715282
N1  - <div data-schema-version="9"><p>This research adopts a reinforcement learning framework to automate GUI testing. The methodological rigour and focus on empirical validation are informative for designing structured experiments.</p>
</div>
KW  - Testing
KW  - Reinforcement Learning
KW  - Experimental Design
ER  - 

